"""
author: sofiane abbar
Create the road network by merging trajectories.
Consume edges one at a time.
"""


import sys
import getopt
from methods import *
from matplotlib import pyplot as plt
from matplotlib import collections as mc
import operator
import copy
import pickle

if __name__ == '__main__':

	# Default parameters
	RADIUS_METER = 35
	SAMPLING_DISTANCE = 20 # sparsification of the edges.
	HEADING_ANGLE_TOLERANCE = 40
	# MAX_PATH_LEN = 20
	# MAX_PATH_DISTANCE_FACTOR = 2.7
	# FILE_CODE = 'data_bbox'
	FILE_CODE = 'data_2015-10-01'
	DATA_PATH = '../data'
	MAP_FILE = 'osmmapclusterangle.txt'

	drawmap = False
	(opts, args) = getopt.getopt(sys.argv[1:], "f:m:p:r:s:a:d:h")
	for o, a in opts:
		if o == "-f":
			FILE_CODE = str(a)
		if o == "-p":
			DATA_PATH = str(a)
		if o == "-r":
			RADIUS_METER = int(a)
		if o == "-s":
			SAMPLING_DISTANCE = int(a)
		if o == "-a":
			HEADING_ANGLE_TOLERANCE = int(a)
		if o == "-d":
			drawmap = True
		if o == "-h":
			print "Usage: python sofa_map.py [-f <file_name>] [-p <file repository>] [-r <clustering_radius>] [-s <sampling_rate>] " \
			      "[-a <heading angle tolerance>] [-h <help>]\n"
			exit()

	RADIUS_DEGREE = RADIUS_METER * 10e-6
	tempFiles = 'load' # or 'dump'

	starting_time = datetime.datetime.now()

	# Read and prepare initial Map if exists:
	print 'building OSM map'
	# clusters, original_osm_clusters_lonlats, roadnet, list_of_edges, edge_weight = \
	# 	build_initial_graph_from_osm_new(cluster_file='../data/osm_clusters_id.txt', edge_file='../data/osm_edges_id.txt')


	if tempFiles == 'load':
		print 'loading files'
		roadnet = pickle.load(open('../data/tempFiles/roadnet.pickle', 'r'))
		clusters = pickle.load(open('../data/tempFiles/clusters.pickle', 'r'))
		clusters_lonlat = pickle.load(open('../data/tempFiles/clusters_lonlat.pickle', 'r'))
		list_of_edges = pickle.load(open('../data/tempFiles/list_of_edges.pickle', 'r'))
		edge_weight = pickle.load(open('../data/tempFiles/edge_weight.pickle', 'r'))
		paths = pickle.load(open('../data/tempFiles/paths.pickle', 'r'))
	elif tempFiles == 'dump':
		osm_shapefile = '../data/shapefiles/doha_roads_matching_kharita.shp'
		simple_osm = build_road_network_from_shapefile(shape_file=osm_shapefile)
		emputed_osm, paths = removePathsOSM(simple_osm, 10)
		clusters, clusters_lonlat, roadnet, list_of_edges, edge_weight = transform_osm_to_our_graph_format(emputed_osm, densification_rate=20)
		# draw_roadnet(roadnet, clusters, paths)
		print 'Dumping files'
		pickle.dump(roadnet, open('../data/tempFiles/roadnet.pickle', 'w'))
		pickle.dump(clusters, open('../data/tempFiles/clusters.pickle', 'w'))
		pickle.dump(clusters_lonlat, open('../data/tempFiles/clusters_lonlat.pickle', 'w'))
		pickle.dump(list_of_edges, open('../data/tempFiles/list_of_edges.pickle', 'w'))
		pickle.dump(edge_weight, open('../data/tempFiles/edge_weight.pickle', 'w'))
		pickle.dump(paths, open('../data/tempFiles/paths.pickle', 'w'))

	# Reading and preparing trajectory data.
	print 'prepare bboxes for data to be considered in the trajectory matching'
	bboxes = []
	for path in paths:
		max_lon = max([point[0] for point in path])
		min_lon = min([point[0] for point in path])
		max_lat = max([point[1] for point in path])
		min_lat = min([point[1] for point in path])
		bboxes.append([max_lon, max_lat, min_lon, min_lat])

	print bboxes
	gps_point_stream = create_gps_stream_from_data(DATA_PATH, FILE_CODE, BBOXES=bboxes)
	print 'number of points:', len(gps_point_stream)

	# KharitaStar parameters:
	parameters = {'file_code': FILE_CODE,
	              'data_path': DATA_PATH,
	              'radius_meter': RADIUS_METER,
	              'radius_degree': RADIUS_DEGREE,
	              'sampling_distance': SAMPLING_DISTANCE,
	              'heading_angle': HEADING_ANGLE_TOLERANCE,
	              'map_file': MAP_FILE,
	              'temp_files': tempFiles,
	              'clusters': clusters,
	              'original_osm_clusters_lonlats': clusters_lonlat,
	              'roadnet': roadnet,
	              'list_of_edges': list_of_edges,
	              'edge_weight': edge_weight,
	              'gps_point_stream': gps_point_stream
	              }

	# if tempFiles == 'dump':
	print 'running kharita star'
	new_osm_clusters=[]
	roadnet, clusters, matched_osm_clusters, new_osm_clusters = kharitaStar_on_imputedOSM(parameters=parameters)
	draw_roadnet(roadnet, clusters, new_clusters=new_osm_clusters, paths=paths, points=gps_point_stream)

	# elif tempFiles == 'load':
	# 	roadnet = pickle.load(open('../data/tempFiles/roadnet.pickle', 'r'))
	# 	clusters = pickle.load(open('../data/tempFiles/clusters.pickle', 'r'))
	# 	matched_osm_clusters = pickle.load(open('../data/tempFiles/matched_clusters.pickle', 'r'))
	# 	new_osm_clusters = pickle.load(open('../data/tempFiles/new_clusters.pickle', 'r'))
	# 	dead_osm_clusters = pickle.load(open('../data/tempFiles/dead_clusters.pickle', 'r'))



	# # get new graph generated by new clusters
	# new_roads = roadnet.subgraph(new_osm_clusters)
	# isolated_nodes = [node for node in new_roads.nodes_iter() if new_roads.degree(node) == 0]
	# new_roads.remove_nodes_from(isolated_nodes)
	# draw_roadnet_id_colored(new_roads, clusters, matched_nodes=new_roads.nodes(), new_nodes=[], dead_nodes=[])
	#
	# # remove from osm unmatched roads
	# # TODO: this is generating a disconnected graph, need to find a better heuristic.
	# roadnet.remove_nodes_from(dead_osm_clusters + new_osm_clusters)
	# isolated_nodes = [node for node in roadnet.nodes_iter() if roadnet.degree(node) == 0]
	# roadnet.remove_nodes_from(isolated_nodes)
	# draw_roadnet_id_colored(roadnet, clusters, matched_nodes=roadnet.nodes(), new_nodes=[], dead_nodes=[])

	# Remove some paths from OSM:
	# removedPaths = removePathsOSM(roadnet,nb_paths=3)

	#draw_roadnet_id_colored(roadnet, clusters, matched_osm_clusters, new_osm_clusters, dead_osm_clusters)
	#newMap = mergeMaps(roadnet, inferredMap)
